{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderType:\n",
    "\tBestPath = 0\n",
    "\tBeamSearch = 1\n",
    "\tWordBeamSearch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model: \n",
    "\t\"minimalistic TF model for HTR\"\n",
    "\n",
    "\t# model constants\n",
    "\tbatchSize = 50\n",
    "\timgSize = (128, 32)\n",
    "\tmaxTextLen = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef __init__(self, charList, decoderType=DecoderType.BestPath, mustRestore=False):\n",
    "\t\t\"init model: add CNN, RNN and CTC and initialize TF\"\n",
    "\t\tself.charList = charList\n",
    "\t\tself.decoderType = decoderType\n",
    "\t\tself.mustRestore = mustRestore\n",
    "\t\tself.snapID = 0\n",
    "\n",
    "\t\t# Whether to use normalization over a batch or a population\n",
    "\t\tself.is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "\t\t# input image batch\n",
    "\t\tself.inputImgs = tf.placeholder(tf.float32, shape=(None, Model.imgSize[0], Model.imgSize[1]))\n",
    "\n",
    "\t\t# setup CNN, RNN and CTC\n",
    "\t\tself.setupCNN()\n",
    "\t\tself.setupRNN()\n",
    "\t\tself.setupCTC()\n",
    "\n",
    "\t\t# setup optimizer to train NN\n",
    "\t\tself.batchesTrained = 0\n",
    "\t\tself.learningRate = tf.placeholder(tf.float32, shape=[])\n",
    "\t\tself.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \n",
    "\t\twith tf.control_dependencies(self.update_ops):\n",
    "\t\t\tself.optimizer = tf.train.RMSPropOptimizer(self.learningRate).minimize(self.loss)\n",
    "\n",
    "\t\t# initialize TF\n",
    "\t\t(self.sess, self.saver) = self.setupTF()\n",
    "\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef setupCNN(self):\n",
    "\t\t\"create CNN layers and return output of these layers\"\n",
    "\t\tcnnIn4d = tf.expand_dims(input=self.inputImgs, axis=3)\n",
    "\n",
    "\t\t# list of parameters for the layers\n",
    "\t\tkernelVals = [5, 5, 3, 3, 3]\n",
    "\t\tfeatureVals = [1, 32, 64, 128, 128, 256]\n",
    "\t\tstrideVals = poolVals = [(2,2), (2,2), (1,2), (1,2), (1,2)]\n",
    "\t\tnumLayers = len(strideVals)\n",
    "\n",
    "\t\t# create layers\n",
    "\t\tpool = cnnIn4d # input to first CNN layer\n",
    "\t\tfor i in range(numLayers):\n",
    "\t\t\tkernel = tf.Variable(tf.truncated_normal([kernelVals[i], kernelVals[i], featureVals[i], featureVals[i + 1]], stddev=0.1))\n",
    "\t\t\tconv = tf.nn.conv2d(pool, kernel, padding='SAME',  strides=(1,1,1,1))\n",
    "\t\t\tconv_norm = tf.layers.batch_normalization(conv, training=self.is_train)\n",
    "\t\t\trelu = tf.nn.relu(conv_norm)\n",
    "\t\t\tpool = tf.nn.max_pool(relu, (1, poolVals[i][0], poolVals[i][1], 1), (1, strideVals[i][0], strideVals[i][1], 1), 'VALID')\n",
    "\n",
    "\t\tself.cnnOut4d = pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef setupRNN(self):\n",
    "\t\t\"create RNN layers and return output of these layers\"\n",
    "\t\trnnIn3d = tf.squeeze(self.cnnOut4d, axis=[2])\n",
    "\n",
    "\t\t# basic cells which is used to build RNN\n",
    "\t\tnumHidden = 256\n",
    "\t\tcells = [tf.contrib.rnn.LSTMCell(num_units=numHidden, state_is_tuple=True) for _ in range(2)] # 2 layers\n",
    "\n",
    "\t\t# stack basic cells\n",
    "\t\tstacked = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "\t\t# bidirectional RNN\n",
    "\t\t# BxTxF -> BxTx2H\n",
    "\t\t((fw, bw), _) = tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked, cell_bw=stacked, inputs=rnnIn3d, dtype=rnnIn3d.dtype)\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t# BxTxH + BxTxH -> BxTx2H -> BxTx1X2H\n",
    "\t\tconcat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t# project output to chars (including blank): BxTx1x2H -> BxTx1xC -> BxTxC\n",
    "\t\tkernel = tf.Variable(tf.truncated_normal([1, 1, numHidden * 2, len(self.charList) + 1], stddev=0.1))\n",
    "\t\tself.rnnOut3d = tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef setupCTC(self):\n",
    "\t\t\"create CTC loss and decoder and return them\"\n",
    "\t\t# BxTxC -> TxBxC\n",
    "\t\tself.ctcIn3dTBC = tf.transpose(self.rnnOut3d, [1, 0, 2])\n",
    "\t\t# ground truth text as sparse tensor\n",
    "\t\tself.gtTexts = tf.SparseTensor(tf.placeholder(tf.int64, shape=[None, 2]) , tf.placeholder(tf.int32, [None]), tf.placeholder(tf.int64, [2]))\n",
    "\n",
    "\t\t# calc loss for batch\n",
    "\t\tself.seqLen = tf.placeholder(tf.int32, [None])\n",
    "\t\tself.loss = tf.reduce_mean(tf.nn.ctc_loss(labels=self.gtTexts, inputs=self.ctcIn3dTBC, sequence_length=self.seqLen, ctc_merge_repeated=True))\n",
    "\n",
    "\t\t# calc loss for each element to compute label probability\n",
    "\t\tself.savedCtcInput = tf.placeholder(tf.float32, shape=[Model.maxTextLen, None, len(self.charList) + 1])\n",
    "\t\tself.lossPerElement = tf.nn.ctc_loss(labels=self.gtTexts, inputs=self.savedCtcInput, sequence_length=self.seqLen, ctc_merge_repeated=True)\n",
    "\n",
    "\t\t# decoder: either best path decoding or beam search decoding\n",
    "\t\tif self.decoderType == DecoderType.BestPath:\n",
    "\t\t\tself.decoder = tf.nn.ctc_greedy_decoder(inputs=self.ctcIn3dTBC, sequence_length=self.seqLen)\n",
    "\t\telif self.decoderType == DecoderType.BeamSearch:\n",
    "\t\t\tself.decoder = tf.nn.ctc_beam_search_decoder(inputs=self.ctcIn3dTBC, sequence_length=self.seqLen, beam_width=50, merge_repeated=False)\n",
    "\t\telif self.decoderType == DecoderType.WordBeamSearch:\n",
    "\t\t\t# import compiled word beam search operation (see https://github.com/githubharald/CTCWordBeamSearch)\n",
    "\t\t\tword_beam_search_module = tf.load_op_library('TFWordBeamSearch.so')\n",
    "\n",
    "\t\t\t# prepare information about language (dictionary, characters in dataset, characters forming words) \n",
    "\t\t\tchars = str().join(self.charList)\n",
    "\t\t\twordChars = open('../model/wordCharList.txt').read().splitlines()[0]\n",
    "\t\t\tcorpus = open('../data/corpus.txt').read()\n",
    "\n",
    "\t\t\t# decode using the \"Words\" mode of word beam search\n",
    "\t\t\tself.decoder = word_beam_search_module.word_beam_search(tf.nn.softmax(self.ctcIn3dTBC, dim=2), 50, 'Words', 0.0, corpus.encode('utf8'), chars.encode('utf8'), wordChars.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef setupTF(self):\n",
    "\t\t\"initialize TF\"\n",
    "\t\tprint('Python: '+sys.version)\n",
    "\t\tprint('Tensorflow: '+tf.__version__)\n",
    "\n",
    "\t\tsess=tf.Session() # TF session\n",
    "\n",
    "\t\tsaver = tf.train.Saver(max_to_keep=1) # saver saves model to file\n",
    "\t\tmodelDir = '../model/'\n",
    "\t\tlatestSnapshot = tf.train.latest_checkpoint(modelDir) # is there a saved model?\n",
    "\n",
    "\t\t# if model must be restored (for inference), there must be a snapshot\n",
    "\t\tif self.mustRestore and not latestSnapshot:\n",
    "\t\t\traise Exception('No saved model found in: ' + modelDir)\n",
    "\n",
    "\t\t# load saved model if available\n",
    "\t\tif latestSnapshot:\n",
    "\t\t\tprint('Init with stored values from ' + latestSnapshot)\n",
    "\t\t\tsaver.restore(sess, latestSnapshot)\n",
    "\t\telse:\n",
    "\t\t\tprint('Init with new values')\n",
    "\t\t\tsess.run(tf.global_variables_initializer())\n",
    "\n",
    "\t\treturn (sess,saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef toSparse(self, texts):\n",
    "\t\t\"put ground truth texts into sparse tensor for ctc_loss\"\n",
    "\t\tindices = []\n",
    "\t\tvalues = []\n",
    "\t\tshape = [len(texts), 0] # last entry must be max(labelList[i])\n",
    "\n",
    "\t\t# go over all texts\n",
    "\t\tfor (batchElement, text) in enumerate(texts):\n",
    "\t\t\t# convert to string of label (i.e. class-ids)\n",
    "\t\t\tlabelStr = [self.charList.index(c) for c in text]\n",
    "\t\t\t# sparse tensor must have size of max. label-string\n",
    "\t\t\tif len(labelStr) > shape[1]:\n",
    "\t\t\t\tshape[1] = len(labelStr)\n",
    "\t\t\t# put each label into sparse tensor\n",
    "\t\t\tfor (i, label) in enumerate(labelStr):\n",
    "\t\t\t\tindices.append([batchElement, i])\n",
    "\t\t\t\tvalues.append(label)\n",
    "\n",
    "\t\treturn (indices, values, shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef decoderOutputToText(self, ctcOutput, batchSize):\n",
    "\t\t\"extract texts from output of CTC decoder\"\n",
    "\t\t\n",
    "\t\t# contains string of labels for each batch element\n",
    "\t\tencodedLabelStrs = [[] for i in range(batchSize)]\n",
    "\n",
    "\t\t# word beam search: label strings terminated by blank\n",
    "\t\tif self.decoderType == DecoderType.WordBeamSearch:\n",
    "\t\t\tblank=len(self.charList)\n",
    "\t\t\tfor b in range(batchSize):\n",
    "\t\t\t\tfor label in ctcOutput[b]:\n",
    "\t\t\t\t\tif label==blank:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\tencodedLabelStrs[b].append(label)\n",
    "\n",
    "\t\t# TF decoders: label strings are contained in sparse tensor\n",
    "\t\telse:\n",
    "\t\t\t# ctc returns tuple, first element is SparseTensor \n",
    "\t\t\tdecoded=ctcOutput[0][0] \n",
    "\n",
    "\t\t\t# go over all indices and save mapping: batch -> values\n",
    "\t\t\tidxDict = { b : [] for b in range(batchSize) }\n",
    "\t\t\tfor (idx, idx2d) in enumerate(decoded.indices):\n",
    "\t\t\t\tlabel = decoded.values[idx]\n",
    "\t\t\t\tbatchElement = idx2d[0] # index according to [b,t]\n",
    "\t\t\t\tencodedLabelStrs[batchElement].append(label)\n",
    "\n",
    "\t\t# map labels to chars for all batch elements\n",
    "\t\treturn [str().join([self.charList[c] for c in labelStr]) for labelStr in encodedLabelStrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef trainBatch(self, batch):\n",
    "\t\t\"feed a batch into the NN to train it\"\n",
    "\t\tnumBatchElements = len(batch.imgs)\n",
    "\t\tsparse = self.toSparse(batch.gtTexts)\n",
    "\t\trate = 0.01 if self.batchesTrained < 10 else (0.001 if self.batchesTrained < 10000 else 0.0001) # decay learning rate\n",
    "\t\tevalList = [self.optimizer, self.loss]\n",
    "\t\tfeedDict = {self.inputImgs : batch.imgs, self.gtTexts : sparse , self.seqLen : [Model.maxTextLen] * numBatchElements, self.learningRate : rate, self.is_train: True}\n",
    "\t\t(_, lossVal) = self.sess.run(evalList, feedDict)\n",
    "\t\tself.batchesTrained += 1\n",
    "\t\treturn lossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef inferBatch(self, batch, calcProbability=False, probabilityOfGT=False):\n",
    "\t\t\"feed a batch into the NN to recognize the texts\"\n",
    "\t\t\n",
    "\t\t# decode, optionally save RNN output\n",
    "\t\tnumBatchElements = len(batch.imgs)\n",
    "\t\tevalList = [self.decoder] + ([self.ctcIn3dTBC] if calcProbability else [])\n",
    "\t\tfeedDict = {self.inputImgs : batch.imgs, self.seqLen : [Model.maxTextLen] * numBatchElements, self.is_train: False}\n",
    "\t\tevalRes = self.sess.run([self.decoder, self.ctcIn3dTBC], feedDict)\n",
    "\t\tdecoded = evalRes[0]\n",
    "\t\ttexts = self.decoderOutputToText(decoded, numBatchElements)\n",
    "\t\t\n",
    "\t\t# feed RNN output and recognized text into CTC loss to compute labeling probability\n",
    "\t\tprobs = None\n",
    "\t\tif calcProbability:\n",
    "\t\t\tsparse = self.toSparse(batch.gtTexts) if probabilityOfGT else self.toSparse(texts)\n",
    "\t\t\tctcInput = evalRes[1]\n",
    "\t\t\tevalList = self.lossPerElement\n",
    "\t\t\tfeedDict = {self.savedCtcInput : ctcInput, self.gtTexts : sparse, self.seqLen : [Model.maxTextLen] * numBatchElements, self.is_train: False}\n",
    "\t\t\tlossVals = self.sess.run(evalList, feedDict)\n",
    "\t\t\tprobs = np.exp(-lossVals)\n",
    "\t\treturn (texts, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef save(self):\n",
    "\t\t\"save model to file\"\n",
    "\t\tself.snapID += 1\n",
    "\t\tself.saver.save(self.sess, '../model/snapshot', global_step=self.snapID)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
