{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "import editdistance\n",
    "from DataLoader import DataLoader, Batch\n",
    "from Model import Model, DecoderType\n",
    "from SamplePreprocessor import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilePaths:\n",
    "\t\"filenames and paths to data\"\n",
    "\tfnCharList = '../model/charList.txt'\n",
    "\tfnAccuracy = '../model/accuracy.txt'\n",
    "\tfnTrain = '../data/'\n",
    "\tfnInfer = '../data/test.png'\n",
    "\tfnCorpus = '../data/corpus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader):\n",
    "\t\"train NN\"\n",
    "\tepoch = 0 # number of training epochs since start\n",
    "\tbestCharErrorRate = float('inf') # best valdiation character error rate\n",
    "\tnoImprovementSince = 0 # number of epochs no improvement of character error rate occured\n",
    "\tearlyStopping = 5 # stop training after this number of epochs without improvement\n",
    "\twhile True:\n",
    "\t\tepoch += 1\n",
    "\t\tprint('Epoch:', epoch)\n",
    "\n",
    "\t\t# train\n",
    "\t\tprint('Train NN')\n",
    "\t\tloader.trainSet()\n",
    "\t\twhile loader.hasNext():\n",
    "\t\t\titerInfo = loader.getIteratorInfo()\n",
    "\t\t\tbatch = loader.getNext()\n",
    "\t\t\tloss = model.trainBatch(batch)\n",
    "\t\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1], 'Loss:', loss)\n",
    "\n",
    "\t\t# validate\n",
    "\t\tcharErrorRate = validate(model, loader)\n",
    "\t\t\n",
    "\t\t# if best validation accuracy so far, save model parameters\n",
    "\t\tif charErrorRate < bestCharErrorRate:\n",
    "\t\t\tprint('Character error rate improved, save model')\n",
    "\t\t\tbestCharErrorRate = charErrorRate\n",
    "\t\t\tnoImprovementSince = 0\n",
    "\t\t\tmodel.save()\n",
    "\t\t\topen(FilePaths.fnAccuracy, 'w').write('Validation character error rate of saved model: %f%%' % (charErrorRate*100.0))\n",
    "\t\telse:\n",
    "\t\t\tprint('Character error rate not improved')\n",
    "\t\t\tnoImprovementSince += 1\n",
    "\n",
    "\t\t# stop training if no more improvement in the last x epochs\n",
    "\t\tif noImprovementSince >= earlyStopping:\n",
    "\t\t\tprint('No more improvement since %d epochs. Training stopped.' % earlyStopping)\n",
    "\t\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "\t\"validate NN\"\n",
    "\tprint('Validate NN')\n",
    "\tloader.validationSet()\n",
    "\tnumCharErr = 0\n",
    "\tnumCharTotal = 0\n",
    "\tnumWordOK = 0\n",
    "\tnumWordTotal = 0\n",
    "\twhile loader.hasNext():\n",
    "\t\titerInfo = loader.getIteratorInfo()\n",
    "\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1])\n",
    "\t\tbatch = loader.getNext()\n",
    "\t\t(recognized, _) = model.inferBatch(batch)\n",
    "\t\t\n",
    "\t\tprint('Ground truth -> Recognized')\t\n",
    "\t\tfor i in range(len(recognized)):\n",
    "\t\t\tnumWordOK += 1 if batch.gtTexts[i] == recognized[i] else 0\n",
    "\t\t\tnumWordTotal += 1\n",
    "\t\t\tdist = editdistance.eval(recognized[i], batch.gtTexts[i])\n",
    "\t\t\tnumCharErr += dist\n",
    "\t\t\tnumCharTotal += len(batch.gtTexts[i])\n",
    "\t\t\tprint('[OK]' if dist==0 else '[ERR:%d]' % dist,'\"' + batch.gtTexts[i] + '\"', '->', '\"' + recognized[i] + '\"')\n",
    "\t\n",
    "\t# print validation result\n",
    "\tcharErrorRate = numCharErr / numCharTotal\n",
    "\twordAccuracy = numWordOK / numWordTotal\n",
    "\tprint('Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate*100.0, wordAccuracy*100.0))\n",
    "\treturn charErrorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, fnImg):\n",
    "\t\"recognize text in image provided by file path\"\n",
    "\timg = preprocess(cv2.imread(fnImg, cv2.IMREAD_GRAYSCALE), Model.imgSize)\n",
    "\tbatch = Batch(None, [img])\n",
    "\t(recognized, probability) = model.inferBatch(batch, True)\n",
    "\tprint('Recognized:', '\"' + recognized[0] + '\"')\n",
    "\tprint('Probability:', probability[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\t\"main function\"\n",
    "\t# optional command line args\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\tparser.add_argument('--train', help='train the NN', action='store_true')\n",
    "\tparser.add_argument('--validate', help='validate the NN', action='store_true')\n",
    "\tparser.add_argument('--beamsearch', help='use beam search instead of best path decoding', action='store_true')\n",
    "\tparser.add_argument('--wordbeamsearch', help='use word beam search instead of best path decoding', action='store_true')\n",
    "\targs = parser.parse_args()\n",
    "\n",
    "\tdecoderType = DecoderType.BestPath\n",
    "\tif args.beamsearch:\n",
    "\t\tdecoderType = DecoderType.BeamSearch\n",
    "\telif args.wordbeamsearch:\n",
    "\t\tdecoderType = DecoderType.WordBeamSearch\n",
    "\n",
    "\t# train or validate on IAM dataset\t\n",
    "\tif args.train or args.validate:\n",
    "\t\t# load training data, create TF model\n",
    "\t\tloader = DataLoader(FilePaths.fnTrain, Model.batchSize, Model.imgSize, Model.maxTextLen)\n",
    "\n",
    "\t\t# save characters of model for inference mode\n",
    "\t\topen(FilePaths.fnCharList, 'w').write(str().join(loader.charList))\n",
    "\t\t\n",
    "\t\t# save words contained in dataset into file\n",
    "\t\topen(FilePaths.fnCorpus, 'w').write(str(' ').join(loader.trainWords + loader.validationWords))\n",
    "\n",
    "\t\t# execute training or validation\n",
    "\t\tif args.train:\n",
    "\t\t\tmodel = Model(loader.charList, decoderType)\n",
    "\t\t\ttrain(model, loader)\n",
    "\t\telif args.validate:\n",
    "\t\t\tmodel = Model(loader.charList, decoderType, mustRestore=True)\n",
    "\t\t\tvalidate(model, loader)\n",
    "\n",
    "\t# infer text on test image\n",
    "\telse:\n",
    "\t\tprint(open(FilePaths.fnAccuracy).read())\n",
    "\t\tmodel = Model(open(FilePaths.fnCharList).read(), decoderType, mustRestore=True)\n",
    "\t\tinfer(model, FilePaths.fnInfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
